import time
import asyncio
import pandas as pd
import io
import os
import google.generativeai as genai
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters
)
from datetime import datetime, timedelta
from collections import OrderedDict
from concurrent.futures import ThreadPoolExecutor

# Configuraci√≥n desde archivo externo
from keys.keys import TELEGRAM_TOKEN, GEMINI_API_KEY

# Configuraci√≥n de seguridad
MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
MAX_USER_REQUESTS = 5  # M√°ximo de solicitudes concurrentes por usuario
DATA_CACHE_TTL = 30 * 60  # 30 minutos en segundos
MAX_CACHED_USERS = 100  # M√°ximo de usuarios en cach√©

# Configurar Gemini
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel(model_name="gemini-1.5-flash")

# Almacenamiento de datos con expiraci√≥n y l√≠mite
user_data = OrderedDict()
executor = ThreadPoolExecutor(max_workers=4)

class CSVSecurity:
    @staticmethod
    def is_valid_csv(content):
        """Verifica si el contenido es un CSV v√°lido"""
        try:
            with io.BytesIO(content) as file_stream:
                pd.read_csv(file_stream, nrows=1)
                return True
        except:
            return False

    @staticmethod
    def is_potentially_malicious(df):
        """Detecta contenido potencialmente malicioso en el DataFrame"""
        suspicious_prefixes = ('=', '+', '-', '@', 'http://', 'https://')
        for col in df.columns:
            if df[col].astype(str).str.startswith(suspicious_prefixes).any():
                return True
        return False

    @staticmethod
    def sanitize_data(df):
        """Sanitiza el DataFrame escapando f√≥rmulas y URLs"""
        return df.applymap(lambda x: f"'{x}" if isinstance(x, str) and x.startswith(
            ('=', '+', '-', '@', 'http://', 'https://')
        ) else x)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Maneja el comando /start"""
    await update.message.reply_text(
        "üëã ¬°Hola! Env√≠ame un archivo *CSV* para analizar:\n\n"
        "üìä CSV - Para datos tabulares\n"
        "(Solo archivos CSV v√°lidos, m√°ximo 100MB)\n\n"
        "‚ö†Ô∏è Por seguridad, los archivos se borran despu√©s de 30 minutos"
    )

async def handle_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Procesa el archivo CSV enviado por el usuario"""
    # Verificar l√≠mite de solicitudes
    if sum(1 for uid in user_data if uid == update.message.chat_id) >= MAX_USER_REQUESTS:
        await update.message.reply_text("‚ö†Ô∏è Has alcanzado el l√≠mite de solicitudes concurrentes.")
        return

    file = await update.message.document.get_file()
    file_name = update.message.document.file_name

    if not file_name.lower().endswith('.csv'):
        await update.message.reply_text("‚ö†Ô∏è Solo se aceptan archivos con extensi√≥n .csv v√°lida.")
        return

    if file.file_size > MAX_FILE_SIZE:
        await update.message.reply_text(
            f"‚ö†Ô∏è Archivo demasiado grande ({(file.file_size/1024/1024):.1f}MB). M√°ximo permitido: 100MB"
        )
        return

    msg = await update.message.reply_text("üì• Descargando y verificando archivo CSV...")

    try:
        content = await file.download_as_bytearray()

        # Verificar que es un CSV v√°lido
        if not CSVSecurity.is_valid_csv(content):
            await msg.edit_text("‚ùå El archivo no es un CSV v√°lido.")
            return

        # Procesar en un hilo separado para no bloquear el event loop
        df, row_count = await asyncio.get_event_loop().run_in_executor(
            executor, process_csv_data, content
        )

        # Sanitizar datos
        if CSVSecurity.is_potentially_malicious(df):
            await msg.edit_text("‚ö†Ô∏è Se detectaron posibles f√≥rmulas/URLs maliciosas. Sanitizando datos...")
            df = CSVSecurity.sanitize_data(df)

        # Almacenar datos con timestamp
        user_data[update.message.chat_id] = {
            'data': df,
            'timestamp': datetime.now(),
            'row_count': row_count,
            'columns': df.columns.tolist()
        }
        
        # Mantener s√≥lo los √∫ltimos MAX_CACHED_USERS
        if len(user_data) > MAX_CACHED_USERS:
            user_data.popitem(last=False)

        await send_file_analysis_response(update, msg, row_count, df.columns)

    except Exception as e:
        await msg.edit_text("‚ùå Error al procesar el archivo. Por favor, verifica que sea un CSV v√°lido.")
        print(f"Error processing file: {e}")

def process_csv_data(content):
    """Procesa el CSV en un hilo separado"""
    with io.BytesIO(content) as file_stream:
        # Primera pasada para contar filas
        row_count = sum(1 for _ in file_stream) - 1
        file_stream.seek(0)
        
        # Leer muestras seg√∫n tama√±o
        if row_count <= 10000:
            df = pd.read_csv(file_stream, encoding='utf-8', on_bad_lines='warn')
        else:
            sample_size = min(10000, max(1000, int(row_count * 0.01)))
            df = pd.read_csv(file_stream, nrows=sample_size, encoding='utf-8', on_bad_lines='warn')
        
        return df, row_count

async def send_file_analysis_response(update, msg, row_count, columns):
    """Env√≠a el resumen del an√°lisis del CSV al usuario"""
    processing_time = time.time() - msg.date.timestamp()
    response = (
        f"‚úÖ CSV analizado ({row_count:,} filas)\n"
        f"‚è± Tiempo: {processing_time:.1f}s\n\n"
        f"üî° Columnas ({len(columns)}):\n{', '.join(columns[:5])}"
    )
    if len(columns) > 5:
        response += f" + {len(columns)-5} m√°s...\n\n"
    response += (
        f"\nüí° Puedes preguntar por:\n"
        f"- An√°lisis de columnas espec√≠ficas\n"
        f"- Estad√≠sticas de los datos\n"
        f"- Patrones o tendencias\n\n"
        f"‚ö†Ô∏è Los datos se borrar√°n en 30 minutos"
    )
    await msg.edit_text(response)

async def handle_question(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Maneja las preguntas del usuario sobre los datos"""
    chat_id = update.message.chat_id
    
    # Verificar datos existentes y expiraci√≥n
    if chat_id not in user_data or (
        datetime.now() - user_data[chat_id]['timestamp'] > timedelta(seconds=DATA_CACHE_TTL)
    ):
        await update.message.reply_text("‚ö†Ô∏è No hay datos activos. Env√≠a un nuevo archivo CSV.")
        if chat_id in user_data:
            user_data.pop(chat_id)
        return

    data_info = user_data[chat_id]
    question = update.message.text.strip()
    df = data_info['data']

    # Respuesta r√°pida para consultas de columnas
    if question.lower() in map(str.lower, data_info['columns']):
        col = next(c for c in data_info['columns'] if c.lower() == question.lower())
        await answer_column_question(update, df, col)
        return

    # Consultas complejas a Gemini
    await handle_gemini_question(update, data_info, question, df)

async def answer_column_question(update, df, col):
    """Responde preguntas espec√≠ficas sobre columnas"""
    sample = df[col].dropna().sample(min(5, len(df))).tolist()
    response = (
        f"üìä Columna: {col}\n"
        f"- Tipo: {df[col].dtype}\n"
        f"- Valores √∫nicos: {df[col].nunique():,}\n"
        f"- Nulos: {df[col].isna().sum():,} ({df[col].isna().mean()*100:.1f}%)\n"
        f"- Ejemplos:\n"
    ) + "\n".join(f"  ‚Ä¢ {str(x)}" for x in sample)
    await update.message.reply_text(response)

async def handle_gemini_question(update, data_info, question, df):
    """Procesa preguntas complejas usando Gemini"""
    msg = await update.message.reply_text("üîç Procesando tu consulta...")

    try:
        # Preparar datos para Gemini
        data_str = (
            f"Muestra de {len(df):,} filas (de {data_info['row_count']:,})\n"
            f"Columnas: {', '.join(data_info['columns'])}\n\n"
            f"Primeras filas:\n{df.head().to_csv(index=False)}\n\n"
            f"Estad√≠sticas:\n{df.describe().to_csv()}"
        )

        prompt = (
            f"Analiza estos datos CSV seg√∫n la pregunta del usuario.\n\n"
            f"Datos:\n{data_str}\n\n"
            f"Pregunta: {question}\n\n"
            f"Instrucciones:\n"
            f"- Responde en espa√±ol de forma clara y concisa\n"
            f"- Incluye an√°lisis cuantitativo cuando sea relevante\n"
            f"- Destaca patrones o anomal√≠as importantes\n"
            f"- Limita la respuesta a 1000 palabras"
        )

        # Ejecutar Gemini en un hilo separado
        response = await asyncio.get_event_loop().run_in_executor(
            executor, model.generate_content, prompt
        )
        
        await msg.edit_text(response.text)

    except Exception as e:
        await msg.edit_text("‚ö†Ô∏è Error al procesar tu consulta. Intenta reformularla.")
        print(f"Gemini error: {e}")

def cleanup_user_data():
    """Limpiar datos expirados"""
    now = datetime.now()
    expired_users = [
        uid for uid, data in user_data.items()
        if now - data['timestamp'] > timedelta(seconds=DATA_CACHE_TTL)
    ]
    for uid in expired_users:
        user_data.pop(uid, None)

async def periodic_cleanup():
    """Limpieza peri√≥dica sin usar JobQueue"""
    while True:
        cleanup_user_data()
        await asyncio.sleep(3600)  # Espera 1 hora

if __name__ == "__main__":
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    
    # Handlers
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.Document.FileExtension("csv"), handle_file))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_question))
    
    # Iniciar tarea de limpieza en segundo plano
    loop = asyncio.get_event_loop()
    loop.create_task(periodic_cleanup())
    
    print("ü§ñ Bot seguro para an√°lisis de CSV funcionando...")
    app.run_polling()
